




  


<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.1/css/academicons.min.css" integrity="sha512-b1ASx0WHgVFL5ZQhTgiPWX+68KjS38Jk87jg7pe+qC7q9YkEtFq0z7xCglv7qGIs/68d3mAp+StfC8WKC5SSAg==" crossorigin="anonymous" referrerpolicy="no-referrer" />
  <link rel="shortcut icon" href="_static/mdakits-empty-favicon-template.svg">
</head>



<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Parallelization Guide &mdash; ZENOWrapper  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/ntd2d.css?v=6fe47884" />

  
    <link rel="shortcut icon" href="_static/mdakits-empty-favicon-template.svg"/>
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=fd6eb6e6"></script>
      <script src="_static/sphinx_highlight.js?v=6ffebe34"></script>
      <script src="_static/js/versions.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Authors" href="authors.html" />
    <link rel="prev" title="Implementation Details" href="implementation.html" />
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-RJSMY46M5C"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-RJSMY46M5C');
  </script>
  <!-- Old DAP UA tag -->
  <script async type="text/javascript" id="_fed_an_ua_tag" src="https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=NIST&subagency=github&pua=UA-66610693-1&yt=true&exts=ppsx,pps,f90,sch,rtf,wrl,txz,m1v,xlsm,msi,xsd,f,tif,eps,mpg,xml,pl,xlt,c">
  </script>

   

  <link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">

  <!-- Load jQuery only if the theme hasn't provided it (keeps RTD themes from double-loading) -->
  <script>
    (function() {
      if (typeof window.jQuery === 'undefined') {
        var jq = document.createElement('script');
        jq.src = 'https://code.jquery.com/jquery-3.6.2.min.js';
        jq.defer = true;
        document.head.appendChild(jq);
      }
    })();
  </script>

  <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>



  <!-- Theme icon fonts moved into proper head block -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.1/css/academicons.min.css" integrity="sha512-b1ASx0WHgVFL5ZQhTgiPWX+68KjS38Jk87jg7pe+qC7q9YkEtFq0z7xCglv7qGIs/68d3mAp+StfC8WKC5SSAg==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-SH9M3SGZK6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-SH9M3SGZK6');
  </script>

  <!-- Optional: Fix NIST footer positioning after injection -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const observer = new MutationObserver(function(mutations) {
        const nistFooter = document.querySelector('[class*="nist-footer"], [id*="nist-footer"], footer[class*="nist"]');
        const nistHeader = document.querySelector('[class*="nist-header"], [id*="nist-header"], header[class*="nist"]');

        if (nistFooter) {
          nistFooter.style.position = 'relative';
          nistFooter.style.marginTop = '2rem';
          nistFooter.style.clear = 'both';
        }

        if (nistHeader) {
          nistHeader.style.position = 'relative';
        }

        if (nistFooter && nistHeader) {
          observer.disconnect();
        }
      });

      observer.observe(document.body, {
        childList: true,
        subtree: true
      });

      setTimeout(function() { observer.disconnect(); }, 5000);
    });
  </script>
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >




  




<a href="index.html">
  
    <img src="_static/zeno_mdakit.png" class="logo" alt="Logo"/>
</a>


  
  
  



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

        </div>
<div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
    
        <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="implementation.html">Implementation Details</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Parallelization Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#two-level-parallelism">Two-Level Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="#architecture">Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="#choosing-a-parallelization-strategy">Choosing a Parallelization Strategy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#many-frames-fast-computation">Many Frames, Fast Computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#few-frames-expensive-computation">Few Frames, Expensive Computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#balanced-workload-hybrid">Balanced Workload (Hybrid)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#performance-comparison">Performance Comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="#backend-selection">Backend Selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#serial-backend">Serial Backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiprocessing-backend">Multiprocessing Backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dask-backend">Dask Backend</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#limitations">Limitations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#trajectory-reader-compatibility">Trajectory Reader Compatibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memory-considerations">Memory Considerations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#best-practices">Best Practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-adaptive-strategy">Example: Adaptive Strategy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Authors</a></li>
</ul>

</div>

      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ZENOWrapper</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Parallelization Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/parallelization.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="parallelization-guide">
<h1>Parallelization Guide<a class="headerlink" href="#parallelization-guide" title="Link to this heading"></a></h1>
<p>ZenoWrapper provides two independent levels of parallelization that can be combined for optimal performance on multi-core systems.</p>
<section id="two-level-parallelism">
<h2>Two-Level Parallelism<a class="headerlink" href="#two-level-parallelism" title="Link to this heading"></a></h2>
<ol class="arabic">
<li><p><strong>Frame-Level Parallelism</strong> (MDAnalysis)</p>
<p>Distributes trajectory frames across multiple Python processes using MDAnalysis’s parallel analysis framework.</p>
</li>
<li><p><strong>Within-Frame Parallelism</strong> (ZENO C++)</p>
<p>Parallelizes Monte Carlo walks within each frame using ZENO’s native C++ threading.</p>
</li>
</ol>
</section>
<section id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Link to this heading"></a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>┌───────────────────────────────────────────────────────────────┐
│          MDAnalysis Multiprocessing (Frame Level)             │
│  Distributes FRAMES across Python processes                   │
├───────────────────────────────────────────────────────────────┤
│  Process 1    │  Process 2    │  Process 3    │  Process 4    │
│  Frames 0-24  │  Frames 25-49 │  Frames 50-74 │  Frames 75-99 │
└───────┬───────┴───────┬───────┴───────┬───────┴───────┬───────┘
        │               │               │               │
        ▼               ▼               ▼               ▼
┌───────────────┐ ┌───────────────┐ ┌───────────────┐ ┌───────────────┐
│ ZENO C++      │ │ ZENO C++      │ │ ZENO C++      │ │ ZENO C++      │
│ Threading     │ │ Threading     │ │ Threading     │ │ Threading     │
│ (Within Frame)│ │ (Within Frame)│ │ (Within Frame)│ │ (Within Frame)│
├───────────────┤ ├───────────────┤ ├───────────────┤ ├───────────────┤
│ Thread 1      │ │ Thread 1      │ │ Thread 1      │ │ Thread 1      │
│ Thread 2      │ │ Thread 2      │ │ Thread 2      │ │ Thread 2      │
│ Thread 3      │ │ Thread 3      │ │ Thread 3      │ │ Thread 3      │
│ Thread 4      │ │ Thread 4      │ │ Thread 4      │ │ Thread 4      │
└───────────────┘ └───────────────┘ └───────────────┘ └───────────────┘

Total Parallelism: 4 processes × 4 threads = 16 parallel computations
</pre></div>
</div>
</section>
<section id="choosing-a-parallelization-strategy">
<h2>Choosing a Parallelization Strategy<a class="headerlink" href="#choosing-a-parallelization-strategy" title="Link to this heading"></a></h2>
<p>The optimal strategy depends on your workload characteristics:</p>
<section id="many-frames-fast-computation">
<h3>Many Frames, Fast Computation<a class="headerlink" href="#many-frames-fast-computation" title="Link to this heading"></a></h3>
<p><strong>Use frame-level parallelism only</strong></p>
<ul class="simple">
<li><p><strong>Configuration</strong>: <code class="docutils literal notranslate"><span class="pre">backend='multiprocessing'</span></code>, <code class="docutils literal notranslate"><span class="pre">n_workers=N_CORES</span></code>, <code class="docutils literal notranslate"><span class="pre">num_threads=1</span></code></p></li>
<li><p><strong>Best for</strong>: Trajectories with &gt;100 frames, <code class="docutils literal notranslate"><span class="pre">n_walks</span></code> &lt; 100,000</p></li>
<li><p><strong>Memory</strong>: N_CORES × base memory (each worker loads full trajectory)</p></li>
<li><p><strong>Scaling</strong>: Near-linear up to ~physical cores</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">MDAnalysis</span> <span class="k">as</span> <span class="nn">mda</span>
<span class="kn">from</span> <span class="nn">zenowrapper</span> <span class="kn">import</span> <span class="n">ZenoWrapper</span>

<span class="n">u</span> <span class="o">=</span> <span class="n">mda</span><span class="o">.</span><span class="n">Universe</span><span class="p">(</span><span class="s1">&#39;topology.pdb&#39;</span><span class="p">,</span> <span class="s1">&#39;trajectory.dcd&#39;</span><span class="p">)</span>  <span class="c1"># 1000 frames</span>

<span class="n">zeno</span> <span class="o">=</span> <span class="n">ZenoWrapper</span><span class="p">(</span>
    <span class="n">u</span><span class="o">.</span><span class="n">atoms</span><span class="p">,</span>
    <span class="n">type_radii</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="mf">1.7</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">:</span> <span class="mf">1.55</span><span class="p">,</span> <span class="s1">&#39;O&#39;</span><span class="p">:</span> <span class="mf">1.52</span><span class="p">},</span>
    <span class="n">n_walks</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span>       <span class="c1"># Moderate computation per frame</span>
    <span class="n">n_interior_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
    <span class="n">num_threads</span><span class="o">=</span><span class="mi">1</span>        <span class="c1"># Single-threaded per frame</span>
<span class="p">)</span>

<span class="c1"># Distribute frames across 16 workers</span>
<span class="n">zeno</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;multiprocessing&#39;</span><span class="p">,</span> <span class="n">n_workers</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="few-frames-expensive-computation">
<h3>Few Frames, Expensive Computation<a class="headerlink" href="#few-frames-expensive-computation" title="Link to this heading"></a></h3>
<p><strong>Use within-frame parallelism only</strong></p>
<ul class="simple">
<li><p><strong>Configuration</strong>: <code class="docutils literal notranslate"><span class="pre">backend='serial'</span></code>, <code class="docutils literal notranslate"><span class="pre">num_threads=N_CORES</span></code></p></li>
<li><p><strong>Best for</strong>: &lt;20 frames, <code class="docutils literal notranslate"><span class="pre">n_walks</span></code> &gt; 1,000,000</p></li>
<li><p><strong>Memory</strong>: 1× base memory (shared across threads)</p></li>
<li><p><strong>Scaling</strong>: 90-95% efficiency (ZENO’s C++ threading is very efficient)</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">u</span> <span class="o">=</span> <span class="n">mda</span><span class="o">.</span><span class="n">Universe</span><span class="p">(</span><span class="s1">&#39;protein.pdb&#39;</span><span class="p">,</span> <span class="s1">&#39;single_frame.pdb&#39;</span><span class="p">)</span>  <span class="c1"># Single frame</span>

<span class="n">zeno</span> <span class="o">=</span> <span class="n">ZenoWrapper</span><span class="p">(</span>
    <span class="n">u</span><span class="o">.</span><span class="n">atoms</span><span class="p">,</span>
    <span class="n">type_radii</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="mf">1.7</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">:</span> <span class="mf">1.55</span><span class="p">,</span> <span class="s1">&#39;O&#39;</span><span class="p">:</span> <span class="mf">1.52</span><span class="p">},</span>
    <span class="n">n_walks</span><span class="o">=</span><span class="mi">10000000</span><span class="p">,</span>    <span class="c1"># Very expensive: 10M walks!</span>
    <span class="n">n_interior_samples</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span>
    <span class="n">num_threads</span><span class="o">=</span><span class="mi">16</span>       <span class="c1"># Multi-threaded ZENO computation</span>
<span class="p">)</span>

<span class="c1"># Process serially but with multi-threaded frames</span>
<span class="n">zeno</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;serial&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="balanced-workload-hybrid">
<h3>Balanced Workload (Hybrid)<a class="headerlink" href="#balanced-workload-hybrid" title="Link to this heading"></a></h3>
<p><strong>Use both levels of parallelism</strong></p>
<ul class="simple">
<li><p><strong>Configuration</strong>: <code class="docutils literal notranslate"><span class="pre">backend='multiprocessing'</span></code>, <code class="docutils literal notranslate"><span class="pre">n_workers=K</span></code>, <code class="docutils literal notranslate"><span class="pre">num_threads=M</span></code> where K×M ≤ N_CORES</p></li>
<li><p><strong>Best for</strong>: Medium trajectories (20-200 frames), moderate computation</p></li>
<li><p><strong>Memory</strong>: K × base memory</p></li>
<li><p><strong>Scaling</strong>: 60-75% efficiency (overhead from both levels)</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">u</span> <span class="o">=</span> <span class="n">mda</span><span class="o">.</span><span class="n">Universe</span><span class="p">(</span><span class="s1">&#39;topology.pdb&#39;</span><span class="p">,</span> <span class="s1">&#39;trajectory.dcd&#39;</span><span class="p">)</span>  <span class="c1"># 100 frames</span>

<span class="n">zeno</span> <span class="o">=</span> <span class="n">ZenoWrapper</span><span class="p">(</span>
    <span class="n">u</span><span class="o">.</span><span class="n">atoms</span><span class="p">,</span>
    <span class="n">type_radii</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="mf">1.7</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">:</span> <span class="mf">1.55</span><span class="p">,</span> <span class="s1">&#39;O&#39;</span><span class="p">:</span> <span class="mf">1.52</span><span class="p">},</span>
    <span class="n">n_walks</span><span class="o">=</span><span class="mi">500000</span><span class="p">,</span>      <span class="c1"># Moderate computation</span>
    <span class="n">n_interior_samples</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span>
    <span class="n">num_threads</span><span class="o">=</span><span class="mi">4</span>        <span class="c1"># 4 threads per frame</span>
<span class="p">)</span>

<span class="c1"># 4 workers × 4 threads = 16 cores total</span>
<span class="n">zeno</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;multiprocessing&#39;</span><span class="p">,</span> <span class="n">n_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="performance-comparison">
<h2>Performance Comparison<a class="headerlink" href="#performance-comparison" title="Link to this heading"></a></h2>
<p>Example: 100 frames, 1,000,000 walks per frame, 16-core machine</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Configuration</p></th>
<th class="head"><p>n_workers</p></th>
<th class="head"><p>num_threads</p></th>
<th class="head"><p>Total Time</p></th>
<th class="head"><p>Memory Usage</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Serial</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>~1000s</p></td>
<td><p>1× (baseline)</p></td>
</tr>
<tr class="row-odd"><td><p>Frame-parallel only</p></td>
<td><p>16</p></td>
<td><p>1</p></td>
<td><p>~65s</p></td>
<td><p>16×</p></td>
</tr>
<tr class="row-even"><td><p>Thread-parallel only</p></td>
<td><p>1</p></td>
<td><p>16</p></td>
<td><p>~100s</p></td>
<td><p>1×</p></td>
</tr>
<tr class="row-odd"><td><p>Hybrid</p></td>
<td><p>4</p></td>
<td><p>4</p></td>
<td><p>~30s</p></td>
<td><p>4×</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Performance numbers are approximate and depend on system architecture,
memory bandwidth, and workload specifics.</p>
</div>
</section>
<section id="backend-selection">
<h2>Backend Selection<a class="headerlink" href="#backend-selection" title="Link to this heading"></a></h2>
<section id="serial-backend">
<h3>Serial Backend<a class="headerlink" href="#serial-backend" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">zeno</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;serial&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Single-process execution</p></li>
<li><p>Always available</p></li>
<li><p>Use with high <code class="docutils literal notranslate"><span class="pre">num_threads</span></code> for within-frame parallelism</p></li>
<li><p>Best for: debugging, single frames, small systems</p></li>
</ul>
</section>
<section id="multiprocessing-backend">
<h3>Multiprocessing Backend<a class="headerlink" href="#multiprocessing-backend" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">zeno</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;multiprocessing&#39;</span><span class="p">,</span> <span class="n">n_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Standard Python multiprocessing</p></li>
<li><p>No additional dependencies</p></li>
<li><p>Good for local multi-core machines</p></li>
<li><p>Each worker gets independent Python process</p></li>
<li><p><strong>Limitation</strong>: Cannot use with streaming readers (e.g., IMDReader)</p></li>
</ul>
</section>
<section id="dask-backend">
<h3>Dask Backend<a class="headerlink" href="#dask-backend" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">zeno</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;dask&#39;</span><span class="p">,</span> <span class="n">n_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Requires <code class="docutils literal notranslate"><span class="pre">dask</span></code> and <code class="docutils literal notranslate"><span class="pre">dask.distributed</span></code> packages</p></li>
<li><p>Supports distributed computing across multiple machines</p></li>
<li><p>More sophisticated scheduling</p></li>
<li><p>Better for very large workloads or clusters</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install dask support</span>
pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;dask[distributed]&quot;</span>
</pre></div>
</div>
</section>
</section>
<section id="limitations">
<h2>Limitations<a class="headerlink" href="#limitations" title="Link to this heading"></a></h2>
<section id="trajectory-reader-compatibility">
<h3>Trajectory Reader Compatibility<a class="headerlink" href="#trajectory-reader-compatibility" title="Link to this heading"></a></h3>
<p>Frame-level parallelization requires trajectory readers that support:</p>
<ol class="arabic simple">
<li><p><strong>Random access</strong>: Ability to seek to arbitrary frames</p></li>
<li><p><strong>Pickling</strong>: Serialization for inter-process communication</p></li>
<li><p><strong>Independent copies</strong>: Each worker creates its own reader instance</p></li>
</ol>
<p><strong>Compatible readers</strong> (most file-based formats):
- DCD, XTC, TRR, NetCDF, HDF5, PDB, etc.</p>
<p><strong>Incompatible readers</strong>:
- <a class="reference external" href="https://docs.mdanalysis.org/stable/documentation_pages/coordinates/IMD.html#MDAnalysis.coordinates.IMD.IMDReader" title="(in MDAnalysis v2.10.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">IMDReader</span></code></a> (streaming, no random access)
- Any custom readers without pickle support</p>
<p>For incompatible readers, use serial backend with within-frame threading:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># IMDReader example (streaming data)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">mda</span><span class="o">.</span><span class="n">Universe</span><span class="p">(</span><span class="s1">&#39;topology.tpr&#39;</span><span class="p">,</span> <span class="s1">&#39;imd://localhost:8889&#39;</span><span class="p">)</span>

<span class="n">zeno</span> <span class="o">=</span> <span class="n">ZenoWrapper</span><span class="p">(</span>
    <span class="n">u</span><span class="o">.</span><span class="n">atoms</span><span class="p">,</span>
    <span class="n">type_radii</span><span class="o">=</span><span class="n">type_radii</span><span class="p">,</span>
    <span class="n">num_threads</span><span class="o">=</span><span class="mi">8</span>  <span class="c1"># Use threading only</span>
<span class="p">)</span>

<span class="c1"># Must use serial backend</span>
<span class="n">zeno</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;serial&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="memory-considerations">
<h3>Memory Considerations<a class="headerlink" href="#memory-considerations" title="Link to this heading"></a></h3>
<p>Each worker in frame-level parallelization loads a complete copy of the trajectory:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Memory usage ≈ n_workers × trajectory_size</span>
<span class="n">memory_needed</span> <span class="o">=</span> <span class="n">n_workers</span> <span class="o">*</span> <span class="n">trajectory_memory_footprint</span>
</pre></div>
</div>
<p>For large trajectories, consider:
- Using fewer workers with more threads per worker
- Processing trajectory in chunks
- Using memory-efficient trajectory formats (e.g., XTC instead of DCD)</p>
</section>
</section>
<section id="best-practices">
<h2>Best Practices<a class="headerlink" href="#best-practices" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p><strong>Start with profiling</strong>: Run a few frames serially to estimate per-frame cost</p></li>
<li><p><strong>Match strategy to workload</strong>: Use guidelines above based on frame count and computation cost</p></li>
<li><p><strong>Monitor memory</strong>: Ensure <code class="docutils literal notranslate"><span class="pre">n_workers</span> <span class="pre">×</span> <span class="pre">trajectory_size</span></code> fits in RAM</p></li>
<li><p><strong>Test scaling</strong>: Verify speedup with small tests before full production runs</p></li>
<li><p><strong>Use fixed seeds</strong>: Set <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter for reproducible parallel results</p></li>
<li><p><strong>Check results</strong>: Compare serial vs parallel runs on small dataset to verify correctness</p></li>
</ol>
<section id="example-adaptive-strategy">
<h3>Example: Adaptive Strategy<a class="headerlink" href="#example-adaptive-strategy" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">MDAnalysis</span> <span class="k">as</span> <span class="nn">mda</span>
<span class="kn">from</span> <span class="nn">zenowrapper</span> <span class="kn">import</span> <span class="n">ZenoWrapper</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span>

<span class="n">u</span> <span class="o">=</span> <span class="n">mda</span><span class="o">.</span><span class="n">Universe</span><span class="p">(</span><span class="s1">&#39;topology.pdb&#39;</span><span class="p">,</span> <span class="s1">&#39;trajectory.dcd&#39;</span><span class="p">)</span>
<span class="n">n_cores</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
<span class="n">n_frames</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">trajectory</span><span class="p">)</span>

<span class="n">type_radii</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="mf">1.7</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">:</span> <span class="mf">1.55</span><span class="p">,</span> <span class="s1">&#39;O&#39;</span><span class="p">:</span> <span class="mf">1.52</span><span class="p">}</span>
<span class="n">n_walks</span> <span class="o">=</span> <span class="mi">1000000</span>

<span class="c1"># Adaptive strategy based on workload</span>
<span class="k">if</span> <span class="n">n_frames</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="ow">and</span> <span class="n">n_walks</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">:</span>
    <span class="c1"># Many frames, fast computation: maximize frame parallelism</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;backend&#39;</span><span class="p">:</span> <span class="s1">&#39;multiprocessing&#39;</span><span class="p">,</span>
        <span class="s1">&#39;n_workers&#39;</span><span class="p">:</span> <span class="n">n_cores</span><span class="p">,</span>
        <span class="s1">&#39;num_threads&#39;</span><span class="p">:</span> <span class="mi">1</span>
    <span class="p">}</span>
<span class="k">elif</span> <span class="n">n_frames</span> <span class="o">&lt;</span> <span class="mi">20</span> <span class="ow">and</span> <span class="n">n_walks</span> <span class="o">&gt;</span> <span class="mi">1000000</span><span class="p">:</span>
    <span class="c1"># Few frames, expensive: maximize thread parallelism</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;backend&#39;</span><span class="p">:</span> <span class="s1">&#39;serial&#39;</span><span class="p">,</span>
        <span class="s1">&#39;n_workers&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;num_threads&#39;</span><span class="p">:</span> <span class="n">n_cores</span>
    <span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Balanced: hybrid approach</span>
    <span class="n">n_workers</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_cores</span> <span class="o">//</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">threads_per_worker</span> <span class="o">=</span> <span class="n">n_cores</span> <span class="o">//</span> <span class="n">n_workers</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;backend&#39;</span><span class="p">:</span> <span class="s1">&#39;multiprocessing&#39;</span><span class="p">,</span>
        <span class="s1">&#39;n_workers&#39;</span><span class="p">:</span> <span class="n">n_workers</span><span class="p">,</span>
        <span class="s1">&#39;num_threads&#39;</span><span class="p">:</span> <span class="n">threads_per_worker</span>
    <span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using strategy: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">zeno</span> <span class="o">=</span> <span class="n">ZenoWrapper</span><span class="p">(</span>
    <span class="n">u</span><span class="o">.</span><span class="n">atoms</span><span class="p">,</span>
    <span class="n">type_radii</span><span class="o">=</span><span class="n">type_radii</span><span class="p">,</span>
    <span class="n">n_walks</span><span class="o">=</span><span class="n">n_walks</span><span class="p">,</span>
    <span class="n">num_threads</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;num_threads&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;backend&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;serial&#39;</span><span class="p">:</span>
    <span class="n">zeno</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;serial&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">zeno</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;backend&#39;</span><span class="p">],</span> <span class="n">n_workers</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;n_workers&#39;</span><span class="p">])</span>
</pre></div>
</div>
</section>
</section>
<section id="see-also">
<h2>See Also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.mdanalysis.org/stable/documentation_pages/analysis/parallelization.html#parallel-analysis" title="(in MDAnalysis v2.10.0)"><span>Parallel analysis</span></a> : MDAnalysis parallel analysis framework</p></li>
<li><p><a class="reference external" href="https://docs.mdanalysis.org/stable/documentation_pages/analysis/base.html#MDAnalysis.analysis.base.AnalysisBase" title="(in MDAnalysis v2.10.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalysisBase</span></code></a> : Base class documentation</p></li>
<li><p><a class="reference external" href="https://zeno.nist.gov/">ZENO Documentation</a> : Algorithm and implementation details</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="implementation.html" class="btn btn-neutral float-left" title="Implementation Details" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="authors.html" class="btn btn-neutral float-right" title="Authors" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Works of NIST employees are not not subject to copyright protection in the United States. Project structure based on the MDAnalysis Cookiecutter version 0.1.</p>
  </div>

  



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
    var versions_json_url = ''
</script>

<div class="rst-versions" data-toggle="rst-versions" role="note"
     aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"></span>
        
      <span class="fa fa-caret-down"></span>
    </span>

    <div class="rst-other-versions">
        <dl id="versionselector">
            <dt>Other Versions</dt>
        </dl>

    </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

   

  <!-- Taken from https://www.filamentgroup.com/lab/html-includes/#another-demo%3A-including-another-html-file -->
  <iframe src="_static/ntd2d_menu.html" onload="this.before((this.contentDocument.body||this.contentDocument).children[0]);this.remove()"></iframe>

</body>
</html>